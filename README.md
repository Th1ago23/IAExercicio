# ğŸ¤– Rede Neural com FunÃ§Ãµes de AtivaÃ§Ã£o ReLU e Sigmoid ğŸš€

![Neural Network](https://media.giphy.com/media/3o7aCTfyhYawdOXcFW/giphy.gif)

## ğŸ“Œ DescriÃ§Ã£o
Este projeto implementa uma rede neural simples para resolver o problema do **XOR**. A rede pode utilizar duas funÃ§Ãµes de ativaÃ§Ã£o diferentes: **ReLU (Rectified Linear Unit)** e **Sigmoid**. O modelo Ã© treinado usando **backpropagation** e comparado em termos de desempenho para ambas as funÃ§Ãµes de ativaÃ§Ã£o.

## ğŸ—ï¸ Estrutura do Modelo
- ğŸŸ¢ **Entrada**: 2 neurÃ´nios (valores binÃ¡rios representando a entrada)
- ğŸ‹ï¸ **Camada Oculta**: 1 camada com 1 neurÃ´nio ativado por ReLU ou Sigmoid
- ğŸ¯ **SaÃ­da**: 1 neurÃ´nio com ReLU ou Sigmoid
- ğŸ“‰ **FunÃ§Ã£o de Erro**: Erro QuadrÃ¡tico MÃ©dio (MSE)
- âš¡ **Otimizador**: Descida do Gradiente com taxa de aprendizado de 0.1

## ğŸ“¦ DependÃªncias
O projeto foi desenvolvido em Python e utiliza as seguintes bibliotecas:
```bash
pip install numpy matplotlib
```

## â–¶ï¸ ExecuÃ§Ã£o
Para executar o treinamento, basta rodar o script Python. O treinamento ocorrerÃ¡ por **10.000 Ã©pocas**, exibindo o erro ao longo das iteraÃ§Ãµes.

### ğŸ”¹ Executar com Sigmoid:
```bash
python sigmoid.ipynb
```

### ğŸ”¹ Executar com ReLU:
```bash
python relu.ipynb
```

Ao final, serÃ¡ exibido um grÃ¡fico mostrando a evoluÃ§Ã£o do erro e os testes da rede com os valores de entrada.

## ğŸ“Š Resultados
O modelo tenta aprender a funÃ§Ã£o XOR atravÃ©s de um aprendizado supervisionado. A saÃ­da esperada para cada entrada Ã©:

| Entrada | SaÃ­da Esperada |
|---------|----------------|
| (0,0)   | 0              |
| (0,1)   | 1              |
| (1,0)   | 1              |
| (1,1)   | 0              |

A rede neural tenta minimizar o erro para que os resultados obtidos se aproximem dos valores esperados. ğŸ“ˆ

ğŸ”¹ **ComparaÃ§Ã£o entre Sigmoid e ReLU:**
- âœ… **Sigmoid** tende a funcionar bem, mas pode sofrer com o problema do **vanishing gradient**, tornando o treinamento mais lento.
- âš¡ **ReLU** pode acelerar o aprendizado, mas Ã© suscetÃ­vel ao problema dos **neurÃ´nios mortos**.

## ğŸ¥ DemonstraÃ§Ã£o Visual
![Training Process](https://media.giphy.com/media/VbnUQpnihPSIgIXuZv/giphy.gif)

## ğŸ‘¨â€ğŸ’» Autor
Este cÃ³digo foi desenvolvido para fins educacionais como parte de um exercÃ­cio de redes neurais. âœ¨
